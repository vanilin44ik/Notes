{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>‚ö°Ô∏è Quick start üèÅ</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.feature_engineering import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –î–∞–Ω–Ω—ã–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –û–ø–∏—Å–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤ (**–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ü–û–¢–†–ê–¢–ò–¢–¨ –ù–ê –≠–¢–û –í–†–ï–ú–Ø**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train.csv\", nrows=None, parse_dates=[])\n",
    "test = pd.read_csv(\"../data/test.csv\", parse_dates=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ó–Ω–∞–∫–æ–º—Å—Ç–≤–æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü—Ä–æ–ø—É—Å–∫–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –í—ã–±—Ä–æ—Å—ã (query boxplot hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = ''\n",
    "target = train[target_name].reset_index(drop=True)\n",
    "train.drop(target_name, axis=1, inplace=True)\n",
    "\n",
    "dataset = pd.concat([train, test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Feature engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **GeoFeatures** (–≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ —à–∏—Ä–∏–Ω–µ-–¥–æ–ª–≥–æ—Ç–µ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–æ—á–∫–∏ –∏–Ω—Ç–µ—Ä–µ—Å–∞ –∏ —Ä–∞–¥–∏—É—Å –ò–º—è: [(–®–∏—Ä–∏–Ω–∞, –î–æ–ª–≥–æ—Ç–∞), –†–∞–¥–∏—É—Å]\n",
    "points = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = add_1geo_features(dataset, 'pickup', points)\n",
    "dataset.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = add_1geo_features(dataset, 'dropoff', points)\n",
    "dataset.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = add_2geo_features(dataset, 'pickup', 'dropoff')\n",
    "dataset.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Timestamp** (–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∏—á)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = add_1time_features(dataset, 'pickup_datetime')\n",
    "dataset.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Memory***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df: pd.DataFrame) -> pd.DataFrame:  \n",
    "    \"\"\"   \n",
    "    –ü—Ä–æ—Ö–æ–¥–∏—Ç –ø–æ –≤—Å–µ–º —Å—Ç–æ–ª–±—Ü–∞–º DataFrame –∏ –∏–∑–º–µ–Ω—è–µ—Ç —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö  \n",
    "    –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏.  \n",
    "    \"\"\"  \n",
    "    start_mem = df.memory_usage().sum() / 1024**2  \n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))  \n",
    "\n",
    "    for col in df.columns:  \n",
    "        col_type = df[col].dtype  \n",
    "\n",
    "        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±—ä–µ–∫—Ç–Ω—ã–µ, –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –∏ datetime64 —Å—Ç–æ–ª–±—Ü—ã  \n",
    "        if col_type in [np.object_, 'category', 'datetime64[ns, UTC]']:  \n",
    "            continue  \n",
    "\n",
    "        c_min = df[col].min()  \n",
    "        c_max = df[col].max()  \n",
    "\n",
    "        # –°–∂–∞—Ç–∏–µ —Ü–µ–ª–æ—á–∏—Å–ª–µ–Ω–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤  \n",
    "        if pd.api.types.is_integer_dtype(col_type):  \n",
    "            if c_min >= np.iinfo(np.int8).min and c_max <= np.iinfo(np.int8).max:  \n",
    "                df[col] = df[col].astype(np.int8)  \n",
    "            elif c_min >= np.iinfo(np.int16).min and c_max <= np.iinfo(np.int16).max:  \n",
    "                df[col] = df[col].astype(np.int16)  \n",
    "            elif c_min >= np.iinfo(np.int32).min and c_max <= np.iinfo(np.int32).max:  \n",
    "                df[col] = df[col].astype(np.int32)  \n",
    "            else:  \n",
    "                df[col] = df[col].astype(np.int64)  \n",
    "\n",
    "        # –°–∂–∞—Ç–∏–µ –≤–µ—â–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤  \n",
    "        elif pd.api.types.is_float_dtype(col_type):  \n",
    "            if c_min >= np.finfo(np.float16).min and c_max <= np.finfo(np.float16).max:  \n",
    "                df[col] = df[col].astype(np.float16)  \n",
    "            elif c_min >= np.finfo(np.float32).min and c_max <= np.finfo(np.float32).max:  \n",
    "                df[col] = df[col].astype(np.float32)  \n",
    "            else:  \n",
    "                df[col] = df[col].astype(np.float64)  \n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2  \n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))  \n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))  \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = reduce_mem_usage(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **INF** -> **NaN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.replace([-np.inf, np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Total***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nunique = dataset.nunique()\n",
    "nunique[nunique == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features2drop = []\n",
    "text_features = []\n",
    "data_features = dataset.select_dtypes('datetime64[ns, UTC]').columns.drop(features2drop, errors='ignore').tolist() # –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "filter_features = dataset.columns.drop(features2drop + data_features, errors='ignore').tolist()\n",
    "cat_features = dataset.select_dtypes(\"object\").columns.drop(text_features + features2drop, errors='ignore').tolist() # –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "num_features = dataset.select_dtypes(\"number\").columns.drop(features2drop, errors='ignore').tolist() # —á–∏—Å–ª–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "\n",
    "print('features2drop :', len(features2drop), features2drop)\n",
    "print('data_features :', len(data_features), data_features)\n",
    "print('cat_features :', len(cat_features), cat_features)\n",
    "print('text_features :', len(text_features), text_features)\n",
    "print('num_features :', len(num_features), num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Preprocessing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_preprocessing = Pipeline([\n",
    "    ('standart_scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[num_features] = pipeline_preprocessing.fit_transform(dataset[num_features]).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features **cat** -> **num**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder()\n",
    "dataset[cat_features] = encoder.fit_transform(dataset[cat_features]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features += cat_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = dataset[:train_size], dataset[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Models regressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Model classifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble:\n",
    "    def __init__(self, *coef):\n",
    "        self.labelencoding = LabelEncoder()\n",
    "\n",
    "        self.catboost = CatBoostClassifier()\n",
    "\n",
    "        self.lgbm_params = None\n",
    "        self.lgbm = LGBMClassifier(**self.lgbm_params)\n",
    "\n",
    "        self.xgb_params = None\n",
    "        self.xgb = XGBClassifier(**self.xgb_params)\n",
    "\n",
    "        self.randomforest_params = None\n",
    "        self.randomforest = RandomForestClassifier(**self.randomforest_params)\n",
    "\n",
    "        self.models = [self.catboost, self.lgbm, self.xgb, self.randomforest]\n",
    "        self.coef = coef\n",
    "        assert len(coef) == len(self.models)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        y = self.labelencoding.fit_transform(y)\n",
    "        for i, model in enumerate(self.models):\n",
    "            if self.coef[i]:\n",
    "                model.fit(X, y)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        proba = 0\n",
    "        for i, model in enumerate(self.models):\n",
    "            if self.coef[i]:\n",
    "                proba += model.predict_proba(X) * self.coef[i]\n",
    "        \n",
    "        return proba\n",
    "    \n",
    "    def get_params(self):\n",
    "        result = f'{self.coef}'\n",
    "\n",
    "        if self.coef[0]:\n",
    "            result += f'\\n - CatBoost: {self.catboost.get_params()}'\n",
    "\n",
    "        if self.coef[1]:\n",
    "            result += f'\\n - LGBM: {self.lgbm_params}'\n",
    "\n",
    "        if self.coef[2]:\n",
    "            result += f'\\n - XGB: {self.xgb_params}'\n",
    "\n",
    "        if self.coef[3]:\n",
    "            result += f'\\n - RandomForest: {self.randomforest_params}'\n",
    "\n",
    "\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_model = None\n",
    "\n",
    "selection_model.fit(train[filter_features], target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = selection_model.get_feature_importance(prettified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances[importances['Importances'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_features = None \n",
    "selected_filter_features = importances['Feature Id'][:count_features]\n",
    "selected_cat_features = list(filter(lambda feature: feature in selected_filter_features, cat_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[selected_filter_features]\n",
    "y = target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Validation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "clfs = []\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    clf = None\n",
    "\n",
    "    clf.fit(X_train, y_train, eval_set=(X_test, y_test))\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    score = root_mean_squared_error(y_test, y_pred)\n",
    "    print(f\"Fold {i + 1} score: {score}\\n\")\n",
    "\n",
    "    scores.append(score)\n",
    "    clfs.append(clf)\n",
    "\n",
    "# –°—á–∏—Ç–∞–µ–º —Å—Ä–µ–¥–Ω–µ–µ –∏ –¥–∏—Å–ø–µ—Ä—Å–∏—é –ø–æ –≤—Å–µ–º —Ñ–æ–ª–¥–∞–º\n",
    "print(f\"Score: {np.mean(scores).round(4)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ—Ç –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞\n",
    "predict = [clf.predict(test[selected_filter_features]) for clf in clfs]\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –≤ –º–∞—Å—Å–∏–≤ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ –æ—Å—Ä–µ–¥–Ω–µ–Ω–∏—è\n",
    "predict = np.mean(predict, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Save** (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–ø–∏—Å–∞—Ç—å —Ñ–∞–π–ª –æ–ø–∏—Å–∞–Ω–∏—è)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "sub = pd.DataFrame(predict)\n",
    "\n",
    "description_path = \"../subs/description.txt\"\n",
    "is_exist = os.path.exists(description_path)\n",
    "\n",
    "with open(\"../subs/description.txt\", \"r+\" if is_exist else \"w\", encoding='utf-8') as file:\n",
    "    if is_exist:\n",
    "        data = ''.join(file.readlines()).split('\\n\\n')\n",
    "\n",
    "    if is_exist and data[-1]:\n",
    "        file.write(\"\\n\\n\")\n",
    "        id = round(float(data[-1].split('\\n')[0][4:]) + 0.1, 1)\n",
    "    else:\n",
    "        id = 1.0\n",
    "\n",
    "    file.write(f\"ID: {id}\\n\")\n",
    "    file.write(f\"LeaderBord Score: \")\n",
    "\n",
    "    sub.to_csv(f\"../subs/submission_{id}.tsv\", sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
